{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjNfNambhfYS"
      },
      "source": [
        "# Important Probability Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZBjnxprhfYS"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6HbL5UFhfYS"
      },
      "source": [
        "We will make use of the `stats` package within the `scipy` suite of tools for scientific python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HEqcCF7uhfYT"
      },
      "outputs": [],
      "source": [
        "import scipy.stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91-nGE2whfYU"
      },
      "source": [
        "## <span style=\"color:Orange\">Overview</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6bPGZvDhfYU"
      },
      "source": [
        "Is this section we provide a brief overview of probability distributions that follows from the previous proabability theory lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE4y8Vh4hfYU"
      },
      "source": [
        "### <span style=\"color:Lightgreen\">What is a Probability Distribution?</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u-Db21lhfYU"
      },
      "source": [
        "A probability distribution is a mathematical function that defines the likelihood of different outcomes or values of a random variable. Probability distributions are fundamental in probability theory and statistics and useful for for analyzing scientific data and making predictions. We more formally refer to these functions as <span style=\"color:violet\">probability density functions</span> (PDFs) when they are normalized to unity such that the intetral over their domain equals 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOKhZ1-shfYU"
      },
      "source": [
        "A brief description of probability distributions, often encountered in practical applications, is presented in the following. The rationale leading to this choice of PDFs is driven either by their specific mathematical properties, and/or in view of their common usage in the modelling of important physical processes; such features are correspondingly emphasized in the discussion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReAa43ZFhfYV"
      },
      "source": [
        "### <span style=\"color:Lightgreen\">Zoology of PDFs in SciPy</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu4hvtnFhfYV"
      },
      "source": [
        "There are many named statistical distributions with useful properties and/or interesting history.  For example, in the [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html) module we find a large number of <span style=\"color:violet\">1D continuous</span> random variable distributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t319XVRxhfYV"
      },
      "outputs": [],
      "source": [
        "len(scipy.stats.rv_continuous.__subclasses__())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvSXLHqVhfYV"
      },
      "source": [
        "and a smaller number of <span style=\"color:violet\">1D discrete</span> distributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR-6HfVThfYV"
      },
      "outputs": [],
      "source": [
        "len(scipy.stats.rv_discrete.__subclasses__())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bazbf2P4hfYV"
      },
      "source": [
        "and <span style=\"color:violet\">multidimensional continuous</span> distributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc7YWZyShfYV"
      },
      "outputs": [],
      "source": [
        "len(scipy.stats._multivariate.multi_rv_generic.__subclasses__())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmtJ2TdlhfYV"
      },
      "source": [
        "## <span style=\"color:Orange\">Some Useful Probabiltiy Distributions</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_LSho_NhfYV"
      },
      "source": [
        "You will likely never need all or even most of these probability distributions in practical application, but it is useful to know about them. Most have special applications that they were created for, but can also be useful as building blocks of an empirical distribution when you just want something that looks like the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZT8wvOKhfYV"
      },
      "source": [
        "\n",
        "\n",
        "### <span style=\"color:Lightgreen\">1D Continuous Distributions</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZfYP-hYhfYV"
      },
      "source": [
        "It is useful to group the large number of 1D continuous distributions according to their general shape. We will use the function below for a quick visual tour of some PDFs in each group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kwIFVzWhfYW"
      },
      "outputs": [],
      "source": [
        "def pdf_demo(xlo, xhi, **kwargs):\n",
        "    x = np.linspace(xlo, xhi, 200)\n",
        "    cmap = sns.color_palette().as_hex()\n",
        "    for i, name in enumerate(kwargs):\n",
        "        for j, arglist in enumerate(kwargs[name].split(';')):\n",
        "            args = eval('dict(' + arglist + ')')\n",
        "            y = eval('scipy.stats.' + name)(**args).pdf(x)\n",
        "            plt.plot(x, y, c=cmap[i], ls=('-','--',':')[j], label=name)\n",
        "    plt.xlim(x[0], x[-1])\n",
        "    plt.legend(fontsize='large')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esXvnYuVhfYW"
      },
      "source": [
        "First, the centered symmetric peaked distributions, including the ubiquitous Gaussian (here called \"norm\" for *normal*) and Lorentzian (here called \"cauchy\").  Each of these can be re-centered using the `loc` (location) parameter and broadened using `scale`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJjvoMG0hfYX"
      },
      "outputs": [],
      "source": [
        "pdf_demo(-5, +5, laplace='scale=1', norm='scale=1', cauchy='scale=1', logistic='scale=1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQVzrX3JhfYX"
      },
      "source": [
        "#### <span style=\"color:violet\">The Gaussian Distribution in 1D and 2D</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmlcFKmehfYX"
      },
      "source": [
        "The Gaussian distribution is commonly found in many scientific applications (and in a wide range of other cases), for example representing the response function of an observable in an experimental apparatus with finite resolution. It is given by\n",
        "\n",
        "$$\\Large P(x; \\mu, \\sigma) = \\frac{1}{{\\sigma \\sqrt{2\\pi}}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$$\n",
        "\n",
        "where\n",
        "* $\\mu$ represents the mean (average) of the distribution.\n",
        "* $\\sigma$ represents the standard deviation of the distribution.\n",
        "* $x$ is the random variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iff1cCk-hfYX"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "mu = 0       # Mean\n",
        "sigma = 1    # Standard deviation\n",
        "\n",
        "# Create data points\n",
        "x = np.linspace(-5, 5, 1000)  # Range of x values\n",
        "\n",
        "# Calculate the 1D Gaussian function\n",
        "gaussian = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
        "\n",
        "# Plot the Gaussian function\n",
        "plt.plot(x, gaussian, label='1D Gaussian')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.title('1D Gaussian Distribution')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#let's check that the Gaussian is a properly normalized PDF\n",
        "# we have 1000 points over dx = 10 so each point is separated by 10/1000; gaussian contains the value of the PDF at each point\n",
        "print(np.sum(gaussian) * 10/1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gaussian can be generalized to multiple dimensions.  \n",
        "\n",
        "In 2D, it can be written generally as:\n",
        "$$ P(x_1, x_2; \\mu_1, \\mu_2, \\sigma_1, \\sigma_2, \\rho) $$\n",
        "$$ =\n",
        "\\frac{1}{{\\sigma_1 \\sigma_2 {2\\pi\\sqrt{1-\\rho^2}}}}  \n",
        "\\exp\\left(-\\frac{1}{2\\left( 1-\\rho^2 \\right)}\n",
        "\\left[\n",
        "  \\left(\\frac{x_1 - \\mu_1}{\\sigma_1}\\right)^2 +\n",
        "  \\left(\\frac{x_2 - \\mu_2}{\\sigma_2}\\right)^2 -\n",
        "  2\\rho \\left( \\frac{x_1-\\mu_1}{\\sigma_1}\\right) \\left( \\frac{x_2 - \\mu_2}{\\sigma_2} \\right)\n",
        " \\right] \\right) $$\n",
        "\n",
        " This contains the expected additional, mean, width and random variable, however\n",
        " there is now an additional parameter $\\rho$.  This is the correlation\n",
        " coefficient between $x_1$ and $x_2$.  This will be discussed more next week, but for now, keep in mind that:\n",
        " - $\\rho = 1$ means $x_1$ and $x_2$ are\n",
        " perfectly correlated,\n",
        " - $\\rho = -1$ means that $x_1$ and $x_2$ are perfectly anti-correlated\n",
        " - $\\rho = 0$ means that $x_1$ and $x_2$ are independent\n",
        "\n",
        " For the higher dimensional case the same pattern is followed though the notation will require vectors and matrices and there are additional correlations.\n",
        "\n"
      ],
      "metadata": {
        "id": "W3K3rG19lbYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-95FYSFhfYX"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "mu_x = 0        # Mean along x-axis\n",
        "mu_y = 0        # Mean along y-axis\n",
        "sigma_x = 1     # Standard deviation along x-axis\n",
        "sigma_y = 1     # Standard deviation along y-axis\n",
        "rho = 0.5       # correlation coefficient\n",
        "\n",
        "# Create a grid of x and y values\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "y = np.linspace(-5, 5, 1000)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# Calculate the 2D Gaussian function\n",
        "gaussian = (\n",
        "    1 / (2 * np.pi * sigma_x * sigma_y * np.sqrt(1-rho*rho))\n",
        ") * np.exp(\n",
        "    -1.0/(2*(1-rho*rho)) *((X - mu_x)**2 / (sigma_x**2) + (Y - mu_y)**2 / (sigma_y**2) -\n",
        "      2*rho*(X - mu_x)*(Y - mu_y)/(sigma_x * sigma_y))\n",
        ")\n",
        "\n",
        "# Plot the 2D Gaussian function as a heatmap\n",
        "plt.imshow(gaussian, cmap='viridis', extent=(-5, 5, -5, 5), origin='lower')\n",
        "plt.colorbar(label='Probability Density')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('2D Gaussian Distribution')\n",
        "plt.show()\n",
        "\n",
        "#let's check that the Gaussian is a properly normalized PDF\n",
        "# we have 1000 points over dx = 10 so each point is separated by 10/1000 and the same division in y;\n",
        "#gaussian contains the value of the PDF at each point\n",
        "print(np.sum(gaussian) * 10/1000 * 10/1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coding up the Gaussian by hand is an interesting exercise, but in general you should use the version available in scipy or some other well validated library."
      ],
      "metadata": {
        "id": "5IJ_P5u8s9sL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWqhEuO7hfYX"
      },
      "source": [
        "#### <span style=\"color:violet\">The Breit-Wigner distribution</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHL6Bre7hfYX"
      },
      "source": [
        "The Breit-Wigner distribution is a probability distribution often used in physics to describe resonances or the shape of spectral lines. It is also known by several other names and variations, depending on the context and field of study. The Breit-Wigner is also called Lorentzian by physicists, and in mathematics circles it is often referred to as the Cauchy distribution.\n",
        "\n",
        "In the context of relativistic kinematics, the Breit-Wigner function provides a good description of a resonant process (for example the invariant mass of decay products from a resonant intermediate state); for a resonance, the parameters x0 and Γ are referred to as its mass and its natural width, respectively.\n",
        "\n",
        "$$\\Large P(x; \\Gamma, x_0) = \\frac{1}{\\pi}\\frac{\\Gamma}{(x - x_0)^2 + \\Gamma^2}$$\n",
        "\n",
        "whose parameters are the most probable value $x_0$ (which specifies the peak of the distribution), and the FWHM $\\Gamma$.\n",
        "\n",
        "With some representative parameters, it look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-nLOqlfhfYY"
      },
      "outputs": [],
      "source": [
        "# Define the Breit-Wigner distribution function\n",
        "def breit_wigner(x, gamma, peak, center):\n",
        "    return (gamma / 2) / ((x - center)**2 + (gamma / 2)**2) + peak\n",
        "\n",
        "# Parameters for the distribution\n",
        "gamma = 2.0  # Width parameter (half-width at half-maximum)\n",
        "peak = 1.0   # Peak height\n",
        "center = 0.0  # Center position\n",
        "\n",
        "# Generate x values\n",
        "x = np.linspace(-10, 10, 400)\n",
        "\n",
        "# Calculate the corresponding y values using the Breit-Wigner function\n",
        "y = breit_wigner(x, gamma, peak, center)\n",
        "\n",
        "# Create a plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x, y, label=f'Breit-Wigner (γ={gamma}, peak={peak}, center={center})')\n",
        "plt.title('Breit-Wigner Distribution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOnOPH4rhfYY"
      },
      "source": [
        "The Breit-Wigner probability distribution has a peculiar feature, as a consequence of its long-range tails: the empirical average and empirical RMS are ill-defined (their variance increase with the size of the samples), and cannot be used as estimators of the Breit-Wigner parameters. The truncated mean and\n",
        "[interquartile range](https://en.wikipedia.org/wiki/Interquartile_range), which are obtained by removing events in the low and high ends of the sample, are\n",
        "safer estimators of the Breit-Wigner parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVavpmpYhfYY"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfHaS18zhfYY"
      },
      "source": [
        "There are also some more specialized asymmetric \"bump\" distributions that are particularly useful for modeling histograms of reconstructed particle masses (even more specialized is the Cruijff function used [here](https://arxiv.org/abs/1005.4087)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkIDEs6FhfYY"
      },
      "outputs": [],
      "source": [
        "pdf_demo(0, 10, crystalball='beta=1,m=3,loc=6;beta=10,m=3,loc=6', argus='chi=0.5,loc=5,scale=2;chi=1.5,loc=5,scale=2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8rEMsbAhfYY"
      },
      "source": [
        "#### <span style=\"color:violet\">The Crystal Ball distribution</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgbmvz5WhfYY"
      },
      "source": [
        "The Crystal Ball function is named after the Crystal Ball Collaboration. The Crystal Ball was a hermetic particle detector used initially with the SPEAR particle accelerator at the Stanford Linear Accelerator Center beginning in 1979. It was designed to detect neutral particles and was used to discover the $\\eta_c$ meson.\n",
        "\n",
        "\n",
        "The Crystal Ball function is a probability density function commonly used to model various lossy processes in high-energy physics. It consists of a Gaussian core portion and a power-law low-end tail, below a certain threshold. The function itself is:\n",
        "\n",
        "$$\\Large\n",
        "f(x; \\alpha, n, \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\left\\{\n",
        "  \\begin{array}{ll}\n",
        "    e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} & \\text{if } \\frac{x - \\mu}{\\sigma} > -\\alpha \\\\\n",
        "    A\\left(B - \\frac{x - \\mu}{\\sigma}\\right)^{-n} & \\text{if } \\frac{x - \\mu}{\\sigma} \\leq -\\alpha\n",
        "  \\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Both the function and its first derivative are both continuous.\n",
        "\n",
        "Crystall Ball functions were used to model the Higgs boson di-photon signal shape in the $H\\to\\gamma\\gamma$ decay channel for the 2012 Higgs boson discovery by the [ATLAS](https://inspirehep.net/literature/1124337) and [CMS](https://inspirehep.net/literature/1124338) Collaborations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-RE13aGhfYY"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0XtUb4QhfYZ"
      },
      "source": [
        "Next, the \"one-sided\" distributions that are only defined for $x \\ge 0$. Most of these smoothly transition from peaking at the origin to peaking at $x > 0$ as some parameter is varied. These are useful building blocks for quantities that must be positive, e.g., errors or densities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq0mQdsthfYZ"
      },
      "outputs": [],
      "source": [
        "pdf_demo(-0.5, 5, gamma='a=1;a=2;a=3', lognorm='s=0.5;s=1.5', chi2='df=2;df=3')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <span style=\"color:violet\">The Gamma distribution</span>"
      ],
      "metadata": {
        "id": "ffWD7L13lktT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gamma distribution can be written as:\n",
        "$$ f(x; a) = \\frac{x^{a-1}e^{-x}}{\\Gamma(a)}\n",
        "$$\n",
        "where $\\Gamma(a)$ is the [gamma *function*](https://en.wikipedia.org/wiki/Gamma_function), not the value of the gamma *distribution* at some value.  There are a couple of other ways to write the gamma distribution but this is the version used in scipy.  $a$ has to be a real positive number.  \n",
        "\n",
        "One reason to discuss the gamma distribution is that other distributions are special cases of it."
      ],
      "metadata": {
        "id": "9INbdu1BlpQs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emyMOnNchfYZ"
      },
      "source": [
        "#### <span style=\"color:violet\">The Exponential distribution</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7FhFdhChfYZ"
      },
      "source": [
        "The exponential distribution is a special case of the Gamma distribution with the shape parameter $a=1$, although the exponential distribution is only supported for $x \\ge 0$. The exponential distribution is one of the widely used continuous distributions. It is often used to model the time elapsed between events, such as the decay of unstable nuclei. A common application of this exponential distribution is the description of phenomena occuring independently at a constant rate, such as decay lengths and lifetimes.\n",
        "\n",
        "It is given by:\n",
        "\n",
        "$$\\Large\n",
        "f(x;\\lambda) =\n",
        "\\begin{cases}\n",
        "\\lambda e^{-\\lambda x} & \\text{for } x \\geq 0 \\\\\n",
        "0 & \\text{for } x < 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $\\lambda$ is the rate parameter and the mean of the distribution.  \n",
        "\n",
        "The classic example of the exponential distribution in the physical world is the decay of an unstable particle.  In this case, $\\lambda$ is the mean lifetime of the particle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtpBSkAhfYZ"
      },
      "source": [
        "#### <span style=\"color:violet\">The Chi-square distribution</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFLLG6OohfYZ"
      },
      "source": [
        "The [chi-square distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution) ($\\chi^2$) is especially useful for parameter fitting, goodness-of-fit measures, and confidence interval calculations. It is given by:\n",
        "\n",
        "$$\\Large f(x;n) = \\frac{1}{{2^{n/2}\\Gamma(n/2)}} x^{(n/2)-1} e^{-x/2}$$\n",
        "\n",
        "where $x$ is the random variable, $n$ is the number of degrees of freedom (which is a positive integer), and $\\Gamma$ is the [gamma function](https://en.wikipedia.org/wiki/Gamma_function) (again not the gamma distribution).\n",
        "\n",
        "The chi-square distribution is another special case of the gamma distribution.  Here we need to set the *scale* parameter on the gamma distribution, but then the gamma distribution with $a=1$ is identical to the chi-square distribution with $df = 2$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_demo(-0.5, 5, gamma='a=1,scale=2', chi2='df=2')"
      ],
      "metadata": {
        "id": "PP6GNjiJvU6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:Lightgreen\">Bounded Distributions</span>"
      ],
      "metadata": {
        "id": "8YfZ4vyixf0Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_UWMEDKhfYa"
      },
      "source": [
        "Another useful group are the \"bounded\" distributions.  These distributions are distinct from the distributions above in that they are defined for a finite range in $x$.\n",
        "\n",
        "The simplest one of these distributions is the *uniform distribution* which is exactly what it sounds like:\n",
        "\n",
        "$$\\Large\n",
        "f(x;a) =\n",
        "\\begin{cases}\n",
        "\\frac{1}{a} & 0 \\leq x \\leq a \\\\\n",
        "0 & otherwise\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_demo(-0.1,2.1,uniform='scale=1;scale=2')"
      ],
      "metadata": {
        "id": "FL4TdAVxx9pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Two other interesting bounded distributions are the *cosine*:\n",
        " $$f(x) = \\frac{1}{2\\pi}\\left(1+\\cos(x)\\right)$$ and defined of the range of $-\\pi \\leq x \\leq \\pi$ and the *beta distribution*."
      ],
      "metadata": {
        "id": "VU--LLoAy2MJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHpljSs4hfYa"
      },
      "outputs": [],
      "source": [
        "pdf_demo(-0.1, 1.1, beta='a=.7,b=.7;a=1.5,b=1.5;a=.9,b=1.5', cosine='loc=0.5,scale=0.159',\n",
        "         uniform='scale=1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gLxq32phfYa"
      },
      "source": [
        "All of the 1D continuous distributions share the same API (via a [common base class](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html)), and allow you to perform useful operations including:\n",
        " - Evaluate the PDF, log(PDF), CDF or log(CDF).\n",
        " - Generate random values from the distribution.\n",
        " - Calculate expectation values of moment functions or even arbitrary functions.\n",
        "\n",
        "The API also allows you to estimate the values of distribution parameters that best describe some data, but we will soon see better approaches to this \"regression\" problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ0g6gfphfYa"
      },
      "outputs": [],
      "source": [
        "def rv_continuous_demo(xlo, xhi, dist, seed=123, n=500):\n",
        "    x = np.linspace(xlo, xhi, 200)\n",
        "    P = dist.pdf(x)\n",
        "    plt.plot(x, P, ls='-', label='PDF $P(x)$')\n",
        "\n",
        "    g = lambda x: (0.7 - 0.3 * (x - xlo) / (xhi - xlo)) * np.percentile(P, 95)\n",
        "    plt.plot(x, g(x), ':', label='$g(x)$')\n",
        "    print('<g> =', dist.expect(g))\n",
        "\n",
        "    gen = np.random.RandomState(seed=seed)\n",
        "    data = dist.rvs(size=n, random_state=gen)\n",
        "    plt.hist(data, range=(xlo, xhi), bins=20, histtype='stepfilled',\n",
        "             alpha=0.25, density=True, stacked = True, label='Random')\n",
        "\n",
        "    plt.ylim(0, None)\n",
        "    plt.grid(axis='y')\n",
        "    plt.legend(loc='upper left', fontsize='large')\n",
        "    rhs = plt.twinx()\n",
        "    rhs.set_ylabel('CDF')\n",
        "    rhs.set_ylim(0., 1.05)\n",
        "    rhs.grid('off')\n",
        "    rhs.plot(x, dist.cdf(x), 'k--')\n",
        "    plt.xlim(xlo, xhi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQLSYxoHhfYa"
      },
      "outputs": [],
      "source": [
        "rv_continuous_demo(-4, +4, scipy.stats.norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLJyTbSzhfYa"
      },
      "outputs": [],
      "source": [
        "rv_continuous_demo(0, 1, scipy.stats.beta(a=1.5,b=0.9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFiSP0SphfYa"
      },
      "source": [
        "### <span style=\"color:Lightgreen\">1D Discrete Distributions</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raAJvVTghfYa"
      },
      "source": [
        "All the distributions above are defined for some range of the real numbers.  However, some distributions are defined only for integers.\n",
        "\n",
        "There are some essential discrete random variable distributions, where the PDF is replaced with what is called in probabilty and statistics a [probability mass function (PMF)](https://en.wikipedia.org/wiki/Probability_mass_function):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu1d0DWPhfYb"
      },
      "outputs": [],
      "source": [
        "def pmf_demo(klo, khi, **kwargs):\n",
        "    k = np.arange(klo, khi + 1)\n",
        "    cmap = sns.color_palette().as_hex()\n",
        "    histopts = {'bins': khi-klo+1, 'range': (klo-0.5,khi+0.5), 'histtype': 'step', 'lw': 2}\n",
        "    for i, name in enumerate(kwargs):\n",
        "        for j, arglist in enumerate(kwargs[name].split(';')):\n",
        "            args = eval('dict(' + arglist + ')')\n",
        "            y = eval('scipy.stats.' + name)(**args).pmf(k)\n",
        "            plt.hist(k, weights=y, color=cmap[i], ls=('-','--',':')[j], label=name, **histopts)\n",
        "    plt.legend(fontsize='large')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we4ozBfNhfYb"
      },
      "source": [
        "The PMF is also known as the <span style=\"color:violet\">discrete probability density function</span> (dPDF). (Again in this area the terminology is non-uniform and generally confusing.  Be careful.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F-mqGyhhfYb"
      },
      "source": [
        "#### <span style=\"color:violet\">The Binomial Distribution</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nT7-djvhfYb"
      },
      "source": [
        "Consider a scenario with two possible outcomes: “success” or “failure”, with a fixed probability $p$ of “success” being realized (this is also called a ___Bernouilli trial___). If $n$ trials are performed, $0 ≤ k ≤ n$ may actually result in “success”; it is assumed that the sequence of trials is irrelevant, and only the number of “success” $k$ is considered of interest. The integer number $k$ follows the so-called [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution) $P(k; n, p)$:\n",
        "\n",
        "$$\\Large P(k; n,p) = \\binom{n}{k} p^k (1-p)^{n-k}$$\n",
        "\n",
        "where $\\binom{n}{k}$ is the binomial coefficient, which can be calculated as\n",
        "\n",
        "$$\\Large \\binom{n}{k} = \\frac{n!}{k!(n-k)!}$$\n",
        "\n",
        "The binomial distribution is related to the beta distribution previously shown, and describes the statistics of ratios of counting measurements (efficiency, purity, completeness, ...):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHrRbG7XhfYb"
      },
      "outputs": [],
      "source": [
        "pmf_demo(0, 10, binom='n=10,p=0.2;n=10,p=0.5;n=10,p=0.8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nme8MiRDhfYb"
      },
      "source": [
        "<span style=\"color:violet\">The Poisson Distribution</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG-u0myIhfYb"
      },
      "source": [
        "In the $n → ∞$, $~p → 0$ limit (with $λ = np$ finite and non-zero) for the Binomial distribution, the random\n",
        "variable $k$ follows the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) $P(k; \\lambda)$,\n",
        "\n",
        "$$\\Large P(k; \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}$$\n",
        "\n",
        "where $\\lambda$ is the rate parameter defining the average rate at which events occur.\n",
        "\n",
        "The Poisson distribution is sometimes called the \"law of rare events\" in view of the $p → 0$ limit. It is a useful model for describing the statistics of event-counting rates in (uncorrelated) counting measurements (which are ubiquitous in astronomy and particle physics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0G6ZNL0hfYb"
      },
      "outputs": [],
      "source": [
        "pmf_demo(0, 10, poisson='mu=2;mu=3;mu=4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLuXSeFNhfYb"
      },
      "source": [
        "Poisson distribution is used to model the number of events occuring in the future, In comparison to the previously described Exponential and Gamma distributions, the Exponential distribution is used to predict the wait time until the very first event, and Gamma distribution is used to predict the wait time until the $\\alpha$-th event."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dranBl00hfYb"
      },
      "source": [
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:violet\">The Gaussian Approximation of the Poisson & Binomial Distributions</span>"
      ],
      "metadata": {
        "id": "LIT0qzO1v3kU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gnuast-hfYc"
      },
      "source": [
        "The Gaussian is also encountered as the limiting distribution for the Binomial and and Poisson ones, in the large $n$ and large $\\lambda$ limits, respectively:\n",
        "\n",
        "$$\\Large P_\\text{binomial} (k; n → ∞, p) → P_\\text{Gauss} (k; np, np(1 − p))$$\n",
        "\n",
        "$$\\Large P_\\text{Poisson} (k; λ → ∞) → P_\\text{Gauss} (k; λ, \\sqrt{\\lambda})$$\n",
        "\n",
        "Note that, when using a Gaussian as approximation, an appropriate continuity correction needs to be taken into account: the range of the Gaussian extends to negative values, while Binomial and Poisson are only defined in the positive range.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fXBPuo8hfYc"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:violet\">Statistical Toolboxes</span>"
      ],
      "metadata": {
        "id": "xHgifnEiwBm5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9IPRD4FhfYc"
      },
      "source": [
        "For a more powerful statistical toolbox than [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html), try the python [statsmodels](http://www.statsmodels.org/) package. Going beyond python, the [R language](https://www.r-project.org/about.html) is designed specifically for \"statistical computing\" (and [integrated in jupyter](https://irkernel.github.io/)), and [RooFit](https://root.cern.ch/roofit-20-minutes) is a \"a toolkit for modeling the expected distribution of events in a physics analysis\" integrated into the [ROOT framework](https://root.cern.ch/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Jj-EgJhfYc"
      },
      "source": [
        "---\n",
        "## <span style=\"color:Orange\">Acknowledgments</span>\n",
        "\n",
        "* Initial version: Mark Neubauer; revisions, Anne Sickles\n",
        "\n",
        "© Copyright 2024"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}